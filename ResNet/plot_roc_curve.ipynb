{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = \"/scratch/wenyuan/Mask_RCNN_On_Pathology/Mask_RCNN/mask_rcnn_coco.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]\n",
      " [  8   8]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.7\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [ 193.95062641  120.83140887  183.74016669]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           prostate\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                800\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "USE_TUMORCLASS                 True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import prostate\n",
    "dataset_dir = \"/scratch/wenyuan/Mask_RCNN_On_Pathology/Data_Pre_Processing/cedars-224\"\n",
    "held_out_set = 0\n",
    "mean_pixel = prostate.Mean_pixel(dataset_dir, held_out_set)\n",
    "class InferenceConfig(prostate.ProstateConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "    DETECTION_NMS_THRESHOLD = 0.7     \n",
    "    MEAN_PIXEL = np.array(mean_pixel)\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.ResNet_Classifier(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  /scratch/wenyuan/Mask_RCNN_On_Pathology/ResNet/logs/prostate20180413T1617-held-out-set0(partial)/mask_rcnn_prostate_0040.h5\n"
     ]
    }
   ],
   "source": [
    "# Get path to saved weights\n",
    "# Either set a specific path, find a trained weights specified by epoch and held_out_set or find last trained weights\n",
    "h5_filename = \"logs/prostate20180413T1617-held-out-set0(partial)/mask_rcnn_prostate_0040.h5\" \n",
    "# Specify the h5 filename here if you want to choose a specific file\n",
    "epoch = -1\n",
    "\n",
    "if h5_filename is not None:\n",
    "    model_path = os.path.join(ROOT_DIR, h5_filename)\n",
    "elif epoch == -1:    \n",
    "    model_path = model.find_last()[1]\n",
    "else:\n",
    "    try:\n",
    "        model_path = model.find_specific(epoch = epoch, held_out_set = held_out_set)[1]\n",
    "    except:\n",
    "        model_path = model.find_specific(epoch = epoch)[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_val = prostate.ProstateDataset()\n",
    "_, val_list = dataset_val.generator_patition(dataset_dir, held_out_set)\n",
    "# val_list = [image for image in val_list if image not in exclude_list]\n",
    "dataset_val.load_prostate(dataset_dir, val_list, mode = 16)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.02673167  0.97326839]] 34.875 14\n",
      "0 [[  2.00949066e-12   1.00000000e+00]] 34.9375 15\n",
      "0 [[ 0.00241592  0.9975841 ]] 36.25 4\n",
      "0 [[  7.56522932e-04   9.99243498e-01]] 36.3125 5\n",
      "0 [[ 0.02651601  0.97348398]] 36.375 6\n",
      "0 [[  4.89959857e-05   9.99951005e-01]] 36.5 8\n",
      "0 [[  1.12337917e-10   1.00000000e+00]] 50.25 4\n",
      "0 [[ 0.26919314  0.73080683]] 58.8125 13\n",
      "1 [[ 0.99888974  0.00111032]] 59.875 14\n",
      "0 [[  1.77786642e-04   9.99822199e-01]] 59.9375 15\n",
      "0 [[ 0.05355411  0.94644588]] 79.125 2\n",
      "0 [[ 0.2006488   0.79935122]] 79.1875 3\n",
      "0 [[ 0.20439368  0.79560632]] 79.4375 7\n",
      "0 [[  1.60756113e-11   1.00000000e+00]] 79.625 10\n",
      "0 [[  7.95017113e-05   9.99920487e-01]] 79.6875 11\n",
      "0 [[ 0.02498595  0.97501409]] 79.9375 15\n",
      "0 [[  8.34215363e-10   1.00000000e+00]] 81.9375 15\n",
      "1 [[  1.00000000e+00   1.14075061e-09]] 85.875 14\n",
      "1 [[  9.99864936e-01   1.35097594e-04]] 85.9375 15\n",
      "1 [[ 0.93465167  0.06534837]] 95.5 8\n",
      "0 [[ 0.10071664  0.89928341]] 97.0 0\n",
      "0 [[ 0.02771444  0.97228563]] 97.125 2\n",
      "0 [[ 0.04850636  0.95149368]] 97.3125 5\n",
      "0 [[  6.38922211e-04   9.99361098e-01]] 97.375 6\n",
      "0 [[  8.91680829e-04   9.99108255e-01]] 97.5625 9\n",
      "0 [[ 0.04850869  0.9514913 ]] 97.625 10\n",
      "0 [[ 0.05325677  0.94674325]] 97.75 12\n",
      "0 [[ 0.05120342  0.94879651]] 97.8125 13\n"
     ]
    }
   ],
   "source": [
    "gt_tumor_class = []\n",
    "pred_tumor_class = []\n",
    "num_wrong_prediction = 0\n",
    "for image_id in dataset_val.image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    tumor_class_gt = 1 \\\n",
    "    if (sum(gt_class_id)) else 0\n",
    "    \n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    gt_tumor_class.append(tumor_class_gt)\n",
    "    pred_tumor_class.append(results[0][1])\n",
    "    if (np.argmax(results[0]) != tumor_class_gt):\n",
    "        print(tumor_class_gt, results, image_id / 16, image_id % 16)\n",
    "        num_wrong_prediction = num_wrong_prediction + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(gt_tumor_class, pred_tumor_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# lw = 2\n",
    "# plt.plot(fpr, tpr, color='darkorange',\n",
    "#          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic example')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save results:\n",
    "# result_dict = {\"fpr\":fpr.tolist(), \"tpr\":tpr.tolist()}\n",
    "# filepath = 'ROC_held_out_%d.csv'%held_out_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open(filepath, \"w\") as outfile:\n",
    "#    writer = csv.writer(outfile)\n",
    "#    writer.writerow(result_dict.keys())\n",
    "#    writer.writerows(zip(*result_dict.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
