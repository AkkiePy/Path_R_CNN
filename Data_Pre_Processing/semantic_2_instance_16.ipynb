{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This ipynb file convert using the whole pic semantic mask to create smaller pathces\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "from prostate_dataset import ProstateDataset\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _ann_padding(annotation_org):\n",
    "        ann_pad = np.lib.pad(annotation_org, ((150, 150), (150, 150), (0, 0)), 'symmetric') \n",
    "        return ann_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _crop_split_image(annotation_org, class_ids, dataset_dir\\\n",
    "                                     height = 600, width = 600, \\\n",
    "                                     image_id = 0, save = False):\n",
    "        imgheight, imgwidth, _ = annotation_org.shape\n",
    "        value = 1\n",
    "        current_image = 0\n",
    "        for i in range(0, imgheight - 301, 300):\n",
    "            for j in range(0, imgwidth - 301, 300):\n",
    "                new_class_ids = []\n",
    "                flag = False\n",
    "                for index in range(len(class_ids)):\n",
    "                    ann_temp = annotation_org[i : i + height, j : j + width, index]\n",
    "                    if value in ann_temp:\n",
    "                        new_class_ids.append(class_ids[index])\n",
    "                        new_instance_mask = np.concatenate((new_instance_mask, np.expand_dims(ann_temp, axis = -1)),\\\n",
    "                                                           axis = -1)\\\n",
    "                        if flag else np.expand_dims(ann_temp, axis = -1)\n",
    "                        flag = True\n",
    "                if save:\n",
    "                    res_dict = {'segmentation': new_instance_mask, 'class_ids': new_class_ids}\n",
    "                    ann_filename = str(image_id).zfill(4) + '_' + str(current_image).zfill(4) + '_instance.mat'\n",
    "                    filepath = os.path.join(dataset_dir, 'masks_instance_mod_16/')\n",
    "                    scipy.io.savemat(filepath + \\\n",
    "                                     ann_filename, res_dict)\n",
    "                    current_image += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done converting image 480!\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data/wenyuan/Path_R_CNN/Data_Pre_Processing'\n",
    "dataset_dir = os.path.join(data_path, 'cedars-224')\n",
    "dataset = ProstateDataset(dataset_dir)\n",
    "\n",
    "start_id = 470\n",
    "end_id = 513\n",
    "display_step = 20\n",
    "\n",
    "for image_id in range(start_id, end_id):\n",
    "    mask, class_ids = dataset.read_instance_ann(image_id)\n",
    "    if mask.ndim == 2:\n",
    "        mask = np.expand_dims(mask, axis = -1)\n",
    "        class_ids = [class_ids]\n",
    "    mask = _ann_padding(mask)\n",
    "    _crop_split_image(mask, class_ids, dataset_dir, image_id = image_id, save = True)\n",
    "    if image_id % display_step ==0:\n",
    "        print('Done converting image %d!' %image_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
