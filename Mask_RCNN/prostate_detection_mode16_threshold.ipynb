{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.io\n",
    "\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "import prostate\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]\n",
      " [  8   8]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        1\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [ 193.97800579  120.89113632  183.79060979]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           prostate\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights from  /scratch/wenyuan/Mask-RCNN/Mask-RCNN-org/Mask_RCNN/logs/prostate20180201T1916/mask_rcnn_prostate_0087.h5\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"/scratch/wenyuan/Mask-RCNN/Data_Pre_Processing/cedars-224\"\n",
    "held_out_set = 4\n",
    "mean_pixel = prostate.Mean_pixel(dataset_dir, held_out_set)\n",
    "class InferenceConfig(prostate.ProstateConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "    DETECTION_NMS_THRESHOLD = 1     \n",
    "    MEAN_PIXEL = np.array(mean_pixel)\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path, find a trained weights specified by epoch and held_out_set or find last trained weights\n",
    "\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "# model_path = model.find_specific(epoch = 9, held_out_set = 4)[1]\n",
    "# model_path = model.find_specific(epoch = 160, held_out_set = held_out_set)[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instance_2_sementic(instance_mask, class_ids):\n",
    "    try:\n",
    "        h, w, d = instance_mask.shape\n",
    "    except ValueError:\n",
    "        mask = int(class_ids) * instance_mask \n",
    "        result_dict = {'ATmask': mask}\n",
    "        return result_dict\n",
    "    \n",
    "    mask_map = {}\n",
    "    for index, label in enumerate(class_ids):\n",
    "        mask_map[str(label)] = np.logical_or(mask_map[str(label)], \\\n",
    "                                             instance_mask[:, :, index]) \\\n",
    "        if str(label) in mask_map.keys() else instance_mask[:, :, index]\n",
    "    \n",
    "    mask = np.zeros((h, w), dtype=np.int)\n",
    "\n",
    "    for key in mask_map.keys():\n",
    "        if (key != '0'):\n",
    "            mask = mask + int(key) * mask_map[key] \n",
    "    result_dict = {'ATmask': mask}\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_2_sementic(mask, class_ids, scores):\n",
    "    \"\"\" convert maskrcnn prediction to 1 single sementic mask\n",
    "    \"\"\"\n",
    "    mask_map = {} # create a probability dict for each class\n",
    "    for index, label in enumerate(class_ids):\n",
    "        mask_map[str(label)] = \\\n",
    "        np.maximum(mask_map[str(label)], scores[index] * mask[:, :, index])\\\n",
    "        if str(label) in mask_map.keys() else scores[index] * mask[:, :, index]\n",
    "    \n",
    "    ## convert to h * w * num_classes probability map\n",
    "    h, w, d = mask.shape\n",
    "    for i in range(4):\n",
    "        try:\n",
    "            sementic_mask = \\\n",
    "            np.concatenate((sementic_mask, \\\n",
    "                            np.expand_dims(mask_map[str(i)], axis = -1)),axis = -1)\\\n",
    "            if (i != 0) else np.expand_dims(mask_map[str(i)], axis = -1)\n",
    "        except KeyError:\n",
    "            sementic_mask = np.concatenate((sementic_mask, np.zeros((h, w, 1))),axis = -1)\\\n",
    "            if (i != 0) else np.zeros((h, w, 1))\n",
    "            \n",
    "    sementic_mask_res = np.argmax(sementic_mask, axis = -1)\n",
    "    return sementic_mask_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_2_whole_slide(patch_list, width_num, height_num):\n",
    "    assert len(patch_list) == width_num * height_num, \"Patch num doesn't match width_num * height_num!\"\n",
    "    row_level = []\n",
    "    for i in range(height_num):\n",
    "        cur_level = np.concatenate(patch_list[i * width_num : (i + 1) * width_num], axis = 1)\n",
    "        row_level.append(cur_level)\n",
    "    return np.concatenate(row_level, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mIOU(c_matrix, th):\n",
    "    \"\"\" compute the mIOU based on the confusion matrix\n",
    "    \"\"\"\n",
    "    num_class, _ = c_matrix.shape\n",
    "    IOU = []\n",
    "    sum_IOU = 0\n",
    "    num_classes = 0\n",
    "    below_th = False\n",
    "    for i in range(num_class):\n",
    "        p = c_matrix[i, i] / (sum(c_matrix[i, :]) + sum(c_matrix[:, i]) - c_matrix[i, i]) \\\n",
    "        if (sum(c_matrix[i, :]) + sum(c_matrix[:, i]) - c_matrix[i, i]) else 0\n",
    "        IOU.append(p)\n",
    "        if p != 0:\n",
    "            sum_IOU += p\n",
    "            num_classes += 1\n",
    "    if sum_IOU / num_classes < th:\n",
    "        below_th = True\n",
    "    return np.mean(IOU), IOU, below_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_val = prostate.ProstateDataset()\n",
    "_, val_list = dataset_val.generator_patition(dataset_dir, held_out_set)\n",
    "# val_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "exclude_list = [394, 185, 506, 289, 360, 7, 222, 406,\\\n",
    "               152, 195, 219, 510, 196, 399, 237, 41,\\\n",
    "               44, 274, 423, 432, 207, 371, 463, 482,\\\n",
    "               176, 50, 494]\n",
    "val_list = [image for image in val_list if image not in exclude_list]\n",
    "dataset_val.load_prostate(dataset_dir, val_list, mode = 16)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating image : 16 !\n",
      "Number of image is: 154\n",
      "mIOU:  0.299705491521 IOU: [0.55768216096569123, 0.0, 0.64113980511985724, 0]\n",
      "Done evaluating image : 32 !\n",
      "Number of image is: 337\n",
      "mIOU:  0.180733680725 IOU: [0.72293472290039062, 0, 0.0, 0.0]\n",
      "Done evaluating image : 48 !\n",
      "Number of image is: 275\n",
      "mIOU:  0.500518282305 IOU: [0.82185472778377566, 0.29257620041753651, 0.88764220101761171, 0]\n",
      "Done evaluating image : 64 !\n",
      "Number of image is: 166\n",
      "mIOU:  0.519623848189 IOU: [0.88814077732380758, 0.0, 0.50173006353910488, 0.68862455189447869]\n",
      "Done evaluating image : 96 !\n",
      "Done evaluating image : 112 !\n",
      "Done evaluating image : 128 !\n",
      "Number of image is: 184\n",
      "mIOU:  0.351646703984 IOU: [0.71935473025755015, 0.68723208567909266, 0.0, 0.0]\n",
      "Done evaluating image : 144 !\n",
      "Number of image is: 331\n",
      "mIOU:  0.338187728106 IOU: [0.73599447553144537, 0, 0.61675643689395643, 0.0]\n",
      "Done evaluating image : 176 !\n",
      "Done evaluating image : 192 !\n",
      "Done evaluating image : 208 !\n",
      "Done evaluating image : 224 !\n",
      "Number of image is: 262\n",
      "mIOU:  0.168315887451 IOU: [0.6732635498046875, 0, 0.0, 0]\n",
      "Done evaluating image : 256 !\n",
      "Done evaluating image : 272 !\n",
      "Number of image is: 496\n",
      "mIOU:  0.368135732267 IOU: [0.70745768302833401, 0.0, 0, 0.76508524604154371]\n",
      "Done evaluating image : 288 !\n",
      "Number of image is: 260\n",
      "mIOU:  0.151559829712 IOU: [0.60623931884765625, 0, 0.0, 0]\n",
      "Done evaluating image : 304 !\n",
      "Number of image is: 5\n",
      "mIOU:  0.493138380056 IOU: [0.31953752985403722, 0.0, 0.83626112267187669, 0.81675486769845229]\n",
      "Number of image is: 240\n",
      "mIOU:  0.537029100623 IOU: [0.77423791482089577, 0.0, 0.53691570156698798, 0.83696278610242059]\n",
      "Done evaluating image : 336 !\n",
      "Done evaluating image : 352 !\n",
      "Done evaluating image : 368 !\n",
      "Done evaluating image : 384 !\n",
      "Done evaluating image : 416 !\n",
      "Number of image is: 80\n",
      "mIOU:  0.327006846401 IOU: [0.5649187261180596, 0.74310865948649474, 0.0, 0.0]\n",
      "Done evaluating image : 432 !\n",
      "Number of image is: 426\n",
      "mIOU:  0.370347702585 IOU: [0.57414358762155293, 0, 0.90724722271696279, 0]\n",
      "Done evaluating image : 448 !\n",
      "Number of image is: 277\n",
      "mIOU:  0.359163592423 IOU: [0.8667036245369536, 0.56995074515365229, 0.0, 0.0]\n",
      "Done evaluating image : 464 !\n",
      "Number of image is: 124\n",
      "mIOU:  0.315736166217 IOU: [0.38580562331493129, 0, 0.87713904155323852, 0]\n",
      "Done evaluating image : 496 !\n",
      "Number of image is: 162\n",
      "mIOU:  0.349747317647 IOU: [0.73712803099342927, 0.6618612395929695, 0.0, 0]\n",
      "Done evaluating image : 512 !\n",
      "Number of image is: 288\n",
      "mIOU:  0.36844228918 IOU: [0.53395834443083157, 0.0, 0.93981081228829255, 0]\n",
      "Done evaluating image : 528 !\n",
      "Number of image is: 251\n",
      "mIOU:  0.322292016972 IOU: [0.8386610096801862, 0.0, 0.45050705820750381, 0]\n",
      "Done evaluating image : 544 !\n",
      "Done evaluating image : 576 !\n",
      "Done evaluating image : 592 !\n",
      "Done evaluating image : 608 !\n",
      "Number of image is: 465\n",
      "mIOU:  0.306724805466 IOU: [0.87359996224461323, 0.35329925961801029, 0.0, 0.0]\n",
      "Done evaluating image : 624 !\n",
      "Number of image is: 72\n",
      "mIOU:  0.334867813011 IOU: [0.59003602842360259, 0, 0.74943522362030424, 0]\n",
      "Done evaluating image : 656 !\n",
      "Number of image is: 187\n",
      "mIOU:  0.374647401712 IOU: [0.597514251004579, 0, 0.90107535584522402, 0]\n",
      "Done evaluating image : 672 !\n",
      "Number of image is: 284\n",
      "mIOU:  0.620254457262 IOU: [0.72421934573286539, 0.49882651225737928, 0.69724178665912218, 0.56073018439688682]\n",
      "Done evaluating image : 688 !\n",
      "Number of image is: 342\n",
      "mIOU:  0.476900349017 IOU: [0.85799929712856349, 0.27115749841735248, 0.77844460052140285, 0]\n",
      "Done evaluating image : 704 !\n",
      "Number of image is: 115\n",
      "mIOU:  0.341766423977 IOU: [0.50959563103471894, 0, 0.85747006487289001, 0.0]\n",
      "Done evaluating image : 736 !\n",
      "Done evaluating image : 752 !\n",
      "Done evaluating image : 768 !\n",
      "Number of image is: 139\n",
      "mIOU:  0.48919763759 IOU: [0.45748722398997205, 0.83071158936545919, 0, 0.66859173700577523]\n",
      "Done evaluating image : 784 !\n",
      "Done evaluating image : 816 !\n",
      "Number of image is: 40\n",
      "mIOU:  0.149618625641 IOU: [0.59847450256347656, 0, 0.0, 0.0]\n",
      "Done evaluating image : 832 !\n",
      "Done evaluating image : 848 !\n",
      "Done evaluating image : 864 !\n",
      "Number of image is: 503\n",
      "mIOU:  0.477578009926 IOU: [0.75659189583852238, 0.0, 0.26812516682750548, 0.88559497703925472]\n",
      "Number of image is: 77\n",
      "mIOU:  0.330791729968 IOU: [0.59780156671314755, 0, 0.72536535315905248, 0]\n",
      "Done evaluating image : 896 !\n",
      "Number of image is: 350\n",
      "mIOU:  0.321798255679 IOU: [0.74240348423010916, 0.54478953848424772, 0.0, 0.0]\n",
      "Done evaluating image : 912 !\n",
      "Done evaluating image : 928 !\n",
      "Done evaluating image : 944 !\n",
      "Number of image is: 430\n",
      "mIOU:  0.338446942604 IOU: [0.68133055326577119, 0.67245721714942253, 0.0, 0.0]\n",
      "Done evaluating image : 976 !\n",
      "Number of image is: 294\n",
      "mIOU:  0.363429636998 IOU: [0.57192216330350076, 0.0, 0.8817963846901794, 0]\n",
      "Done evaluating image : 992 !\n",
      "Number of image is: 12\n",
      "mIOU:  0.547972501258 IOU: [0.87637237336472651, 0.47432709314747035, 0.0, 0.84119053851990222]\n",
      "Done evaluating image : 1008 !\n",
      "Number of image is: 499\n",
      "mIOU:  0.172365665436 IOU: [0.68946266174316406, 0, 0.0, 0.0]\n",
      "Done evaluating image : 1024 !\n",
      "Done evaluating image : 1056 !\n",
      "Done evaluating image : 1072 !\n",
      "Done evaluating image : 1088 !\n",
      "Number of image is: 459\n",
      "mIOU:  0.332756494661 IOU: [0.65424718613437505, 0, 0.67677879250827644, 0]\n",
      "Done evaluating image : 1104 !\n",
      "Done evaluating image : 1136 !\n",
      "Number of image is: 312\n",
      "mIOU:  0.470384252011 IOU: [0.79096110836794564, 0.32926607440391736, 0.7613098252722208, 0]\n",
      "Done evaluating image : 1152 !\n",
      "Number of image is: 142\n",
      "mIOU:  0.305019053145 IOU: [0.34773240624121743, 0, 0.8723438063400295, 0]\n",
      "Done evaluating image : 1168 !\n",
      "Number of image is: 100\n",
      "mIOU:  0.747983398299 IOU: [0.86599951025465138, 0.55502419264093616, 0.74573441420575182, 0.82517547609526043]\n",
      "Done evaluating image : 1184 !\n",
      "Number of image is: 128\n",
      "mIOU:  0.525466991934 IOU: [0.65512895662368109, 0.71400059394871074, 0.0, 0.73273841716243016]\n"
     ]
    }
   ],
   "source": [
    "height_crop = [128, 384]\n",
    "width_crop = [128, 384]\n",
    "\n",
    "for image_id in range(0, len(dataset_val.image_ids), 16):\n",
    "    image_whole = []\n",
    "    gt_mask_whole = []\n",
    "    pred_mask_whole = []\n",
    "    for i in range(16):\n",
    "        # Load image and ground truth data\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset_val, inference_config,\n",
    "                                   image_id + i, use_mini_mask=False)\n",
    "        image_whole.append(image[height_crop[0] : height_crop[1], width_crop[0] : width_crop[1]])\n",
    "\n",
    "        # Convert gt-instance mask to gt-sementic mask\n",
    "        gt_sementic_mask = instance_2_sementic(gt_mask, gt_class_id)\n",
    "        gt_mask_whole.append(gt_sementic_mask['ATmask'][height_crop[0] : height_crop[1], width_crop[0] : width_crop[1]])\n",
    "\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        # Convert prediction to sementic mask\n",
    "        result_sementic = prediction_2_sementic(r['masks'], r['class_ids'], r['scores'])\\\n",
    "        if r['class_ids'].size != 0 else np.zeros((image.shape[0], image.shape[1]))   \n",
    "        pred_mask_whole.append(result_sementic[height_crop[0] : height_crop[1], width_crop[0] : width_crop[1]])\n",
    "    img = combine_2_whole_slide(image_whole, 4, 4)\n",
    "    ann = combine_2_whole_slide(gt_mask_whole, 4, 4)\n",
    "    pred = combine_2_whole_slide(pred_mask_whole, 4, 4)\n",
    "    c_matrix = confusion_matrix(np.ravel(ann), np.ravel(pred))\n",
    "    if c_matrix.size != 16:\n",
    "            \"\"\"if the confusion matrix is not 4 by 4\n",
    "            \"\"\"\n",
    "            unique_set = \\\n",
    "            np.union1d(np.unique(pred), \\\n",
    "                       np.unique(ann))\n",
    "            xv, yv = np.meshgrid(unique_set, unique_set)\n",
    "            temp = np.zeros((4, 4))\n",
    "            temp[yv.astype(int), xv.astype(int)] = c_matrix\n",
    "            c_matrix = temp \n",
    "\n",
    "    mIOU, IOU, below_th = compute_mIOU(c_matrix, th = 0.75)\n",
    "    if below_th:\n",
    "        print(\"Number of image is:\", val_list[int(image_id / 16)])\n",
    "        print(\"mIOU: \", mIOU, \"IOU:\", IOU)\n",
    "    if image_id % (16 * 5):\n",
    "        print(\"Done evaluating image : %d !\" %image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
