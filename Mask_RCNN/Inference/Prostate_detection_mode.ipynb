{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Detection on Prostate Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to use trained Mask R-CNN on prostate dataset for a whole tile. As for large pathology image, we crop each image to several patches. This notebook is designed to get the detection reulst for single pic first and combine them back to the whole image. You'd need a GPU, though, because the network backbone is a Resnet101, which would be slow to detect on a CPU.\n",
    "\n",
    "The code of the Prostate dataset can be found in prostate.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module from system lib\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module from maskrcnn repo\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "import prostate\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \\\n",
    "     create_pairwise_gaussian, softmax_to_unary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Specify GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dir that store the prostate dataset\n",
    "# dataset_dir = os.path.join(os.path.dirname(os.getcwd()), \"Data_Pre_Processing/cedars-224\")\n",
    "dataset_dir = os.path.join(\"/data/wenyuan/Path_R_CNN\", \"Data_Pre_Processing/cedars-224\")\n",
    "# We do 5-fold validation, specify which fold to be exclude for the current run\n",
    "held_out_set = 0\n",
    "# Featch the mean_pixel based on the training data (data exclude the held_out_set)\n",
    "mean_pixel = prostate.Mean_pixel(dataset_dir, held_out_set)\n",
    "# Configuration\n",
    "class DetectionConfig(prostate.ProstateConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    DETECTION_NMS_THRESHOLD = 1     \n",
    "    MEAN_PIXEL = np.array(mean_pixel)\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    DETECTION_CROP = [128, 384, 128, 384] # [height_crop_start, height_crop_end, width_crop_start, width_crop_end]\n",
    "    MODE = 16\n",
    "    POST_PROCESSING = True\n",
    "    USE_TUMORCLASS = True\n",
    "detection_config = DetectionConfig()\n",
    "detection_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Graph and Loading Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"detection\", \n",
    "                          config=detection_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "# Get path to saved weights\n",
    "# Either set a specific path, find a trained weights specified by epoch and held_out_set or find last trained weights\n",
    "h5_filename = None # Specify the h5 filename here if you want to choose a specific file\n",
    "epoch = 71\n",
    "\n",
    "if h5_filename is not None:\n",
    "    model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "elif epoch == -1:    \n",
    "    model_path = model.find_last()[1]\n",
    "else:\n",
    "    try:\n",
    "        model_path = model.find_specific(epoch = epoch, held_out_set = held_out_set)[1]\n",
    "    except:\n",
    "        model_path = model.find_specific(epoch = epoch)[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset and Specify the Interested Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random = False # whether to randomly choose the image\n",
    "# Specify the image that is interested in\n",
    "val_list = [236]\n",
    "# val_list = [image for image in val_list if image not in exclude_list]\n",
    "if Random:\n",
    "    _, val_list = dataset_val.generator_patition(dataset_dir, held_out_set)    \n",
    "    image_id = random.choice(val_list)\n",
    "    print(\"Image_ID:\", image_id)\n",
    "    val_list = [image_id]\n",
    "    image_patch_num = np.random.randint(0, detection_config.MODE)\n",
    "\n",
    "dataset_val = prostate.ProstateDataset()\n",
    "dataset_val.load_prostate(dataset_dir, val_list, mode = detection_config.MODE)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_whole = []\n",
    "gt_mask_whole = []\n",
    "det_mask_whole = []\n",
    "det_probs_whole = []\n",
    "hv, wv = utils.create_crop_region(detection_config) # meshgrid for crop region\n",
    "for i in range(detection_config.MODE):\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, detection_config,\n",
    "                               i, use_mini_mask=False)\n",
    "    gt_tumor_class = 1 if (sum(gt_class_id)) else 0\n",
    "    \n",
    "    image_whole.append(image[hv, wv])\n",
    "    # Convert gt-instance mask to gt-sementic mask\n",
    "    gt_sementic_mask = utils.instance_2_sementic(gt_mask, gt_class_id)\n",
    "    gt_sementic_mask = gt_sementic_mask['ATmask']\n",
    "    gt_sementic_mask = gt_sementic_mask[hv, wv]\n",
    "    gt_mask_whole.append(gt_sementic_mask)\n",
    "\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    # TODO: modify this part\n",
    "    if np.argmax(r['tumor_probs']) == 1:\n",
    "        det_sementic_mask = r['sementic_mask']\n",
    "        det_sementic_probs = r['prob_mask']\n",
    "    else:\n",
    "        det_sementic_mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "        det_sementic_probs = np.zeros((image.shape[0], image.shape[1], detection_config.NUM_CLASSES))\n",
    "        det_sementic_probs[:, :, 0] = 1\n",
    "        \n",
    "    det_mask_whole.append(det_sementic_mask[hv, wv])\n",
    "    det_probs_whole.append(det_sementic_probs[hv, wv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Patches to Whole Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_num = int(math.sqrt(detection_config.MODE)) # how many patches in each row or col\n",
    "img = utils.combine_2_whole_slide(image_whole, rc_num, rc_num)\n",
    "ann = utils.combine_2_whole_slide(gt_mask_whole, rc_num, rc_num)\n",
    "det = utils.combine_2_whole_slide(det_mask_whole, rc_num, rc_num)\n",
    "prob = utils.combine_2_whole_slide(det_probs_whole, rc_num, rc_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Field Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detection_config.POST_PROCESSING:\n",
    "    # change the prob (0, 0, 0, 0) item to (1, 0, 0 ,0)\n",
    "    index_0, index_1 = np.where((prob == (0, 0, 0, 0)).all(axis = 2))\n",
    "    prob[index_0, index_1, :] = (0.99, 0.01 / 3, 0.01 / 3, 0.01 / 3)\n",
    "    # move the probability axis to assure that the first dimension is the class dimension\n",
    "    prob_move = np.moveaxis(prob, 2, 0)\n",
    "    # The input should be the negative of the logarithm of probability values\n",
    "    # Look up the definition of the softmax_to_unary for more information\n",
    "    unary = softmax_to_unary(prob_move)\n",
    "    # The inputs should be C-continious -- we are using Cython wrapper\n",
    "    unary = np.ascontiguousarray(unary)\n",
    "    d = dcrf.DenseCRF(img.shape[0] * img.shape[1], 4)\n",
    "    d.setUnaryEnergy(unary)\n",
    "    # This potential penalizes small pieces of segmentation that are\n",
    "    # spatially isolated -- enforces more spatially consistent segmentations\n",
    "    feats = create_pairwise_gaussian(sdims=(20, 20), shape=img.shape[:2])\n",
    "    d.addPairwiseEnergy(feats, compat=3,\n",
    "                        kernel=dcrf.DIAG_KERNEL,\n",
    "                        normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    Q = d.inference(5)\n",
    "    post_processing = np.argmax(Q, axis=0).reshape((img.shape[0], img.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization the sementic map\n",
    "visualize.display_sementic(img, ann,\n",
    "                            figsize=(8, 8))\n",
    "visualize.display_sementic(img, det,\n",
    "                            figsize=(8, 8))\n",
    "if detection_config.POST_PROCESSING:\n",
    "    visualize.display_sementic(img, post_processing,\n",
    "                            figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Before and After Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(np.ravel(ann), np.ravel(det))\n",
    "c_matrix = utils.expand_c_matrix(c_matrix, detection_config.NUM_CLASSES, ann, det)\n",
    "mIOU, IOU, below_th = utils.compute_mIOU(c_matrix, th = 0.5)\n",
    "print('Confusion Matrix:\\n', c_matrix)\n",
    "print(' mIOU:', mIOU, '\\n', \n",
    "      'IOU for each class:', IOU, '\\n',\n",
    "      'Below_th:', below_th)\n",
    "if detection_config.POST_PROCESSING:\n",
    "    c_matrix = confusion_matrix(np.ravel(ann), np.ravel(post_processing))\n",
    "    c_matrix = utils.expand_c_matrix(c_matrix, detection_config.NUM_CLASSES, ann, post_processing)\n",
    "    mIOU, IOU, below_th = utils.compute_mIOU(c_matrix, th = 0.5)\n",
    "    print('Post Processing Evaluation \\n'' Confusion Matrix:\\n', c_matrix)\n",
    "    print(' mIOU:', mIOU, '\\n', \n",
    "          'IOU for each class:', IOU, '\\n',\n",
    "          'Below_th:', below_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save Probability Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_map_dict = {'prob_mask': prob}\n",
    "file_name = \"probs_map/\" + str(val_list[0]).zfill(4) + '_sementic_probs.mat'\n",
    "file_path = os.path.join(dataset_dir, file_name)\n",
    "utils.save_sementic(file_path, prob_map_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
