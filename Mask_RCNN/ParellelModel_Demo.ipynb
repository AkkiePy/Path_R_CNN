{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "\n",
    "\n",
    "class ParallelModel(KM.Model):\n",
    "    \"\"\"Subclasses the standard Keras Model and adds multi-GPU support.\n",
    "    It works by creating a copy of the model on each GPU. Then it slices\n",
    "    the inputs and sends a slice to each copy of the model, and then\n",
    "    merges the outputs together and applies the loss on the combined\n",
    "    outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keras_model, gpu_count):\n",
    "        \"\"\"Class constructor.\n",
    "        keras_model: The Keras model to parallelize\n",
    "        gpu_count: Number of GPUs. Must be > 1\n",
    "        \"\"\"\n",
    "        self.inner_model = keras_model\n",
    "        self.gpu_count = gpu_count\n",
    "        merged_outputs = self.make_parallel()\n",
    "        super(ParallelModel, self).__init__(inputs=self.inner_model.inputs,\n",
    "                                            outputs=merged_outputs)\n",
    "\n",
    "    def __getattribute__(self, attrname):\n",
    "        \"\"\"Redirect loading and saving methods to the inner model. That's where\n",
    "        the weights are stored.\"\"\"\n",
    "        if 'load' in attrname or 'save' in attrname:\n",
    "            return getattr(self.inner_model, attrname)\n",
    "        return super(ParallelModel, self).__getattribute__(attrname)\n",
    "\n",
    "    def summary(self, *args, **kwargs):\n",
    "        \"\"\"Override summary() to display summaries of both, the wrapper\n",
    "        and inner models.\"\"\"\n",
    "        super(ParallelModel, self).summary(*args, **kwargs)\n",
    "        self.inner_model.summary(*args, **kwargs)\n",
    "\n",
    "    def make_parallel(self):\n",
    "        \"\"\"Creates a new wrapper model that consists of multiple replicas of\n",
    "        the original model placed on different GPUs.\n",
    "        \"\"\"\n",
    "        # Slice inputs. Slice inputs on the CPU to avoid sending a copy\n",
    "        # of the full inputs to all GPUs. Saves on bandwidth and memory.\n",
    "        input_slices = {name: tf.split(x, self.gpu_count)\n",
    "                        for name, x in zip(self.inner_model.input_names,\n",
    "                                           self.inner_model.inputs)}\n",
    "\n",
    "        output_names = self.inner_model.output_names\n",
    "        outputs_all = []\n",
    "        for i in range(len(self.inner_model.outputs)):\n",
    "            outputs_all.append([])\n",
    "\n",
    "        # Run the model call() on each GPU to place the ops there\n",
    "        for i in range(self.gpu_count):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('tower_%d' % i):\n",
    "                    # Run a slice of inputs through this replica\n",
    "                    zipped_inputs = zip(self.inner_model.input_names,\n",
    "                                        self.inner_model.inputs)\n",
    "                    inputs = [\n",
    "                        KL.Lambda(lambda s: input_slices[name][i],\n",
    "                                  output_shape=lambda s: (None,) + s[1:])(tensor)\n",
    "                        for name, tensor in zipped_inputs]\n",
    "                    # Create the model replica and get the outputs\n",
    "                    outputs = self.inner_model(inputs)\n",
    "                    if not isinstance(outputs, list):\n",
    "                        outputs = [outputs]\n",
    "                    # Save the outputs for merging back together later\n",
    "                    for l, o in enumerate(outputs):\n",
    "                        outputs_all[l].append(o)\n",
    "\n",
    "        # Merge outputs on CPU\n",
    "        with tf.device('/cpu:0'):\n",
    "            merged = []\n",
    "            for outputs, name in zip(outputs_all, output_names):\n",
    "                # If outputs are numbers without dimensions, add a batch dim.\n",
    "                def add_dim(tensor):\n",
    "                    \"\"\"Add a dimension to tensors that don't have any.\"\"\"\n",
    "                    if K.int_shape(tensor) == ():\n",
    "                        return KL.Lambda(lambda t: K.reshape(t, [1, 1]))(tensor)\n",
    "                    return tensor\n",
    "                outputs = list(map(add_dim, outputs))\n",
    "\n",
    "                # Concatenate\n",
    "                merged.append(KL.Concatenate(axis=0, name=name)(outputs))\n",
    "        return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras.optimizers\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0, 1\"\n",
    "\n",
    "GPU_COUNT = 2\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs/parallel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(x_train, num_classes):\n",
    "    # Reset default graph. Keras leaves old ops in the graph,\n",
    "    # which are ignored for execution but clutter graph\n",
    "    # visualization in TensorBoard.\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    inputs = KL.Input(shape=x_train.shape[1:], name=\"input_image\") # input doesn't have batch dimension\n",
    "    x = KL.Conv2D(32, (3, 3), activation='relu', padding=\"same\",\n",
    "                  name=\"conv1\")(inputs)\n",
    "    x = KL.Conv2D(64, (3, 3), activation='relu', padding=\"same\",\n",
    "                  name=\"conv2\")(x)\n",
    "    x = KL.MaxPooling2D(pool_size=(2, 2), name=\"pool1\")(x)\n",
    "    x = KL.Flatten(name=\"flat1\")(x)\n",
    "    x = KL.Dense(128, activation='relu', name=\"dense1\")(x)\n",
    "    x = KL.Dense(num_classes, activation='softmax', name=\"dense2\")(x)\n",
    "\n",
    "    return KM.Model(inputs, x, \"digit_classifier_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST Data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype('float32') / 255\n",
    "x_test = np.expand_dims(x_test, -1).astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build data generator and model\n",
    "datagen = ImageDataGenerator()\n",
    "model = build_model(x_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add multi-GPU support.\n",
    "model = ParallelModel(model, GPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, clipnorm=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 5s 109ms/step - loss: 1.3780 - acc: 0.5766 - val_loss: 0.5303 - val_acc: 0.8311\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.4426 - acc: 0.8691 - val_loss: 0.3850 - val_acc: 0.8805\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.3571 - acc: 0.8953 - val_loss: 0.3092 - val_acc: 0.9108\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.2977 - acc: 0.9087 - val_loss: 0.2713 - val_acc: 0.9171\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.2596 - acc: 0.9266 - val_loss: 0.2093 - val_acc: 0.9368\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.2097 - acc: 0.9344 - val_loss: 0.1890 - val_acc: 0.9423\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.1891 - acc: 0.9397 - val_loss: 0.1832 - val_acc: 0.9422\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.1775 - acc: 0.9450 - val_loss: 0.1646 - val_acc: 0.9530\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.1604 - acc: 0.9537 - val_loss: 0.1275 - val_acc: 0.9603\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.1571 - acc: 0.9509 - val_loss: 0.1283 - val_acc: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4317c3588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit_generator(\n",
    "    datagen.flow(x_train, y_train, batch_size=64),\n",
    "    steps_per_epoch=50, epochs=10, verbose=1,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[keras.callbacks.TensorBoard(log_dir=MODEL_DIR,\n",
    "                                           write_graph=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
