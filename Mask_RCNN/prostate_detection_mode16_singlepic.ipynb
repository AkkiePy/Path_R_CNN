{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.io\n",
    "\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "import prostate\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]\n",
      " [  8   8]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        1\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [ 193.97800579  120.89113632  183.79060979]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           prostate\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "USE_TUMORCLASS                 True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights from  /scratch/wenyuan/Mask_RCNN_On_Pathology/Mask_RCNN/logs/prostate20180223T1554-held-out-4/mask_rcnn_prostate_0071.h5\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'tumor_class_dense' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5616d6566e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Provide path to trained weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/wenyuan/Mask_RCNN_On_Pathology/Mask_RCNN/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2191\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2192\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wenyuan/.conda/envs/maskrcnn/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3181\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3182\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3183\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3184\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3185\u001b[0m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweight_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/wenyuan/.conda/envs/maskrcnn/lib/python3.5/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'tumor_class_dense' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "dataset_dir = \"/scratch/wenyuan/Mask_RCNN_On_Pathology/Data_Pre_Processing/cedars-224\"\n",
    "held_out_set = 4\n",
    "mean_pixel = prostate.Mean_pixel(dataset_dir, held_out_set)\n",
    "class InferenceConfig(prostate.ProstateConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    DETECTION_NMS_THRESHOLD = 1     \n",
    "    MEAN_PIXEL = np.array(mean_pixel)\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_DIM = 512\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path, find a trained weights specified by epoch and held_out_set or find last trained weights\n",
    "\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "# model_path = model.find_last()[1]\n",
    "# model_path = model.find_specific(epoch = 9, held_out_set = 4)[1]\n",
    "# model_path = model.find_specific(epoch = 75, held_out_set = held_out_set)[1]\n",
    "model_path = model.find_specific(epoch = 71)[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instance_2_sementic(instance_mask, class_ids):\n",
    "    try:\n",
    "        h, w, d = instance_mask.shape\n",
    "    except ValueError:\n",
    "        mask = int(class_ids) * instance_mask \n",
    "        result_dict = {'ATmask': mask}\n",
    "        return result_dict\n",
    "    \n",
    "    mask_map = {}\n",
    "    for index, label in enumerate(class_ids):\n",
    "        mask_map[str(label)] = np.logical_or(mask_map[str(label)], \\\n",
    "                                             instance_mask[:, :, index]) \\\n",
    "        if str(label) in mask_map.keys() else instance_mask[:, :, index]\n",
    "    \n",
    "    mask = np.zeros((h, w), dtype=np.int)\n",
    "\n",
    "    for key in mask_map.keys():\n",
    "        if (key != '0'):\n",
    "            mask = mask + int(key) * mask_map[key] \n",
    "    result_dict = {'ATmask': mask}\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_2_sementic(mask, class_ids, scores):\n",
    "    \"\"\" convert maskrcnn prediction to 1 single sementic mask\n",
    "    \"\"\"\n",
    "    mask_map = {} # create a probability dict for each class\n",
    "    for index, label in enumerate(class_ids):\n",
    "        mask_map[str(label)] = \\\n",
    "        np.maximum(mask_map[str(label)], scores[index] * mask[:, :, index])\\\n",
    "        if str(label) in mask_map.keys() else scores[index] * mask[:, :, index]\n",
    "    \n",
    "    ## convert to h * w * num_classes probability map\n",
    "    h, w, d = mask.shape\n",
    "    for i in range(4):\n",
    "        try:\n",
    "            sementic_mask = \\\n",
    "            np.concatenate((sementic_mask, \\\n",
    "                            np.expand_dims(mask_map[str(i)], axis = -1)),axis = -1)\\\n",
    "            if (i != 0) else np.expand_dims(mask_map[str(i)], axis = -1)\n",
    "        except KeyError:\n",
    "            sementic_mask = np.concatenate((sementic_mask, np.zeros((h, w, 1))),axis = -1)\\\n",
    "            if (i != 0) else np.zeros((h, w, 1))\n",
    "            \n",
    "    sementic_mask_res = np.argmax(sementic_mask, axis = -1)\n",
    "    return sementic_mask_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_val = prostate.ProstateDataset()\n",
    "val_list = [277]\n",
    "# _, val_list = dataset_val.generator_patition(dataset_dir, held_out_set)\n",
    "# # val_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# # exclude_list_held_out_4 = [394, 185, 506, 289, 360, 7, 222, 406,\\\n",
    "# #                152, 195, 219, 510, 196, 399, 237, 41,\\\n",
    "# #                44, 274, 423, 432, 207, 371, 463, 482,\\\n",
    "# #                176, 50, 494]\n",
    "# exclude_list = [394, 185, 506, 289, 360, 7, 222, 406,\\\n",
    "#                152, 195, 219, 510, 196, 399, 237, 41,\\\n",
    "#                44, 274, 423, 432, 207, 371, 463, 482,\\\n",
    "#                176, 50, 494]\n",
    "# val_list = [image for image in val_list if image not in exclude_list]\n",
    "dataset_val.load_prostate(dataset_dir, val_list, mode = 16)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height_crop = [128, 384]\n",
    "width_crop = [128, 384]\n",
    "# height_crop = [64, 192]\n",
    "# width_crop = [64, 192]\n",
    "image_id = random.choice(val_list)\n",
    "image_id = val_list.index(image_id) * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_patch_num = 13 # from 0 to 15\n",
    "# Load image and ground truth data\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config,\n",
    "                           image_id + image_patch_num, use_mini_mask=False)\n",
    "tumor_class_gt = 1 \\\n",
    "if (sum(gt_class_id)) else 0\n",
    "image_crop = image[height_crop[0] : height_crop[1], width_crop[0] : width_crop[1]]\n",
    "# Convert gt-instance mask to gt-sementic mask\n",
    "gt_sementic_mask = instance_2_sementic(gt_mask, gt_class_id)\n",
    "gt_sementic_mask_crop = gt_sementic_mask['ATmask'][height_crop[0] : height_crop[1], width_crop[0] : width_crop[1]]\n",
    "\n",
    "# Run object detection\n",
    "results = model.detect([image], verbose=0)\n",
    "r = results[0]\n",
    "\n",
    "# Convert prediction to sementic mask\n",
    "result_sementic = prediction_2_sementic(r['masks'], r['class_ids'], r['scores'])\\\n",
    "if r['class_ids'].size != 0 else np.zeros((image.shape[0], image.shape[1]))   \n",
    "\n",
    "pred_mask_crop = result_sementic[height_crop[0] : height_crop[1], width_crop[0] : width_crop[1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization the sementic map\n",
    "visualize.display_sementic(image_crop, gt_sementic_mask_crop,\n",
    "                            figsize=(8, 8))\n",
    "visualize.display_sementic(image_crop, pred_mask_crop, \n",
    "                            figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r['tumor_probs'], tumor_class_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
